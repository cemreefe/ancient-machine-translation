{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import element\n",
    "import urllib\n",
    "import re\n",
    "\n",
    "html_page = urllib.request.urlopen(\"http://etcsl.orinst.ox.ac.uk/cgi-bin/etcsl.cgi?text=all#\")\n",
    "soup = BeautifulSoup(html_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "\n",
    "for link in soup.findAll('a'):\n",
    "    link_list.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref = \"http://etcsl.orinst.ox.ac.uk/cgi-bin/\"\n",
    "paired_links = []\n",
    "\n",
    "for i in range(len(link_list)-1):\n",
    "    if \"text=c\" in link_list[i] and \"text=t\" in link_list[i+1]:\n",
    "        paired_links.append(pref + link_list[i])\n",
    "        paired_links.append(pref + link_list[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_pairs = np.reshape(np.array(paired_links), (-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first parse translation to understand what sentences should be concatenated.\n",
    "\n",
    "tips = []\n",
    "\n",
    "# http://etcsl.orinst.ox.ac.uk/cgi-bin/etcsl.cgi?text=c.1.1.2&display=Crit&charenc=gcirc#\n",
    "\n",
    "for i in range(len(link_pairs)):  \n",
    "    \n",
    "    print(i, \"\\t\", link_pairs[i][0])\n",
    "    html_page = urllib.request.urlopen(link_pairs[i][0])\n",
    "    soup = BeautifulSoup(html_page, \"html5\") # \"xml\" parser is significantly faster but freezes.\n",
    "    \n",
    "    for span in soup.findAll('span'):\n",
    "        tip = span.get('onMouseover')\n",
    "        if not tip == None:\n",
    "            tip = tip[18:-2]\n",
    "            tip = re.sub(\"<sub>|</sub>\", \"\", tip)\n",
    "            tip = re.sub(\" \\(.*\\) \", \";\", tip)\n",
    "            tip = re.sub(\";to be \", \";\", tip)\n",
    "            tip = re.sub(\";to \", \";\", tip)\n",
    "            tip = re.sub(\"soothing expression\", \"oh\", tip)\n",
    "            tip = re.sub(\"\\?\", \"\", tip)\n",
    "\n",
    "            ## information loss\n",
    "            tip = re.sub(\" *\\(.+\\)\", \"\", tip)\n",
    "            \n",
    "            tips.append(tip)\n",
    "    \n",
    "    if i%3 == 2:\n",
    "        print(\"i sleep\")\n",
    "        time.sleep(10)\n",
    "\n",
    "print(\"{}\\ttokens\".format(len(tips)))\n",
    "unique_tips = np.unique(tips)\n",
    "print(\"{}\\tunique tokens\".format(len(unique_tips)))\n",
    "\n",
    "## Inspect this closer to remove unwanted pairs.\n",
    "\n",
    "unique_pairs = [i.replace('', '').split(\";\") for i in unique_tips]\n",
    "\n",
    "# If RHS has \",\" then split RHS and add both parts as different pairs\n",
    "for pair in unique_pairs:\n",
    "    if len(pair)!=2:\n",
    "        unique_pairs.remove(pair)\n",
    "    elif \",\" in pair[1]:\n",
    "        rhs = pair[1].split(\", \")\n",
    "        unique_pairs.append([pair[0], rhs[0]])\n",
    "        unique_pairs.append([pair[0], rhs[1]])\n",
    "        unique_pairs.remove(pair)\n",
    "        \n",
    "now   = datetime.now() # current date and time\n",
    "stamp = now.strftime(\"%Y%m%d%H%M\")        \n",
    "\n",
    "pd.DataFrame(unique_pairs).to_csv(\"data/unique_tip_pairs_all.csv\", \";\", index=None, header=[\"akk\", \"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pairs = pd.read_csv(\"data/unique_tip_pairs_all.csv\", \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True if given \"num\", line number is between a given line number range.\n",
    "# Takes into consideration the line numbers that end in letters, i.e. \"49A-49J.\"\n",
    "\n",
    "def lesstoe(ran, num):\n",
    "    \n",
    "    if len(re.findall(r\"[0-9]*-?[0-9]*\\.\", ran)) == 0 or len(re.findall(r\"[0-9]*\\.\", num)) == 0:\n",
    "        return True\n",
    "    \n",
    "        \n",
    "    offset = 54\n",
    "    \n",
    "    ran = ran[:-1]\n",
    "    \n",
    "    if num == \"\":\n",
    "        num = \"p\"\n",
    "    \n",
    "    if not num[0].isdigit():\n",
    "        num = \"0.\"\n",
    "        \n",
    "    num = num[:-1]\n",
    "    \n",
    "    drange = ran.split(\"-\")\n",
    "    \n",
    "    \n",
    "    if len(drange) == 2:\n",
    "        drange.append(num)\n",
    "        \n",
    "\n",
    "        for i in range(3):\n",
    "            \n",
    "            if len(drange[i])>2:\n",
    "                if drange[i][-2].isalpha():\n",
    "                    drange[i] = drange[i][:-2] + \".\" + repr(9) + drange[i][-1]\n",
    "                    drange[i] = drange[i][:4] + re.sub(\"\\.\", \"\", drange[i][4:])\n",
    "            \n",
    "            if len(drange[i])>1:\n",
    "                if drange[i][-1].isalpha():\n",
    "                    drange[i] = re.sub(drange[i][-1], \".\" + repr(ord(drange[i][-1])-offset),drange[i])\n",
    "                    drange[i] = drange[i][:4] + re.sub(\"\\.\", \"\", drange[i][4:])\n",
    "\n",
    "                    \n",
    "        #print(drange)\n",
    "        try:\n",
    "            return (float(drange[2]) <= float(drange[1])) or float(drange[2]) == 0\n",
    "        except:\n",
    "            print(drange[2], drange[1], drange[2])\n",
    "\n",
    "    else:\n",
    "        #print(drange)\n",
    "        return ran != num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_list     = []\n",
    "sentences_list = []\n",
    "ltrs_list      = []\n",
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=348\n",
    "conts_list = pd.read_csv(\"data/sentence_pairs_{}.csv\".format(j), \";\").to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#j=0 works \n",
    "while j!=len(link_pairs):\n",
    "    \n",
    "    #translation\n",
    "\n",
    "    conts = []\n",
    "    nums = []\n",
    "\n",
    "    print(j, \"\\t\", link_pairs[j][1])\n",
    "    html_page = urllib.request.urlopen(link_pairs[j][1])\n",
    "    soup = BeautifulSoup(html_page, \"html5\") # \"xml\" parser is significantly faster but freezes.\n",
    "\n",
    "    for a in soup.findAll(\"p\"):\n",
    "        c = a.contents\n",
    "        if len(c) != 0:\n",
    "            for i in range(len(c)):\n",
    "                if type(c[i]) is element.Tag:\n",
    "                    try:\n",
    "                        c[i] = \"\".join(c[i].contents)\n",
    "                    except:\n",
    "                        for k in range(len(c[i])):\n",
    "                            s = str(c[i].contents[k])\n",
    "                            s = re.sub(\"<span class=\\\"note\\\">.*?\\\"proper\\\">|</span></span>\", \"\", s)\n",
    "                            c[i].contents[k] = s\n",
    "                        c[i] = \"\".join(c[i].contents)\n",
    "            conts.append(c)\n",
    "\n",
    "    for a in soup.findAll(\"a\"):\n",
    "        c = a.contents\n",
    "        if len(c) != 0:\n",
    "            if c[0].isdigit:\n",
    "                nums.append(c)\n",
    "\n",
    "    for i in range(len(conts)):\n",
    "        conts[i][1] = \"\".join(conts[i][1:])\n",
    "        conts[i][1] = re.sub(\"\\(.*?\\)\", \"\", conts[i][1])\n",
    "        conts[i][1] = re.sub(\"  \", \" \", conts[i][1])\n",
    "        del conts[i][3:]\n",
    "\n",
    "    del conts[-1]\n",
    "\n",
    "\n",
    "\n",
    "    ## transliteration\n",
    "\n",
    "    ltrs = []\n",
    "\n",
    "    print(j, \"\\t\", link_pairs[j][0])\n",
    "    html_page = urllib.request.urlopen(link_pairs[j][0])\n",
    "    soup = BeautifulSoup(html_page, \"html5\") # \"xml\" parser is significantly faster but freezes.\n",
    "\n",
    "    for a in soup.findAll(\"td\"):\n",
    "        c = a.contents\n",
    "        if len(c) != 0:\n",
    "            for i in range(len(c)):\n",
    "                if type(c[i]) is element.Tag:\n",
    "                    s = str(c[i])\n",
    "\n",
    "                    s = re.sub(\"<span onMouseover.*?;\", \"\", s)\n",
    "\n",
    "                    s = re.sub(\" -- \", \" \", s)\n",
    "                    s = re.sub(\"<phr.*/phr>\", \"\", s)\n",
    "                    s = re.sub(\"<font.*/font>\", \"\", s)\n",
    "                    s = re.sub(\"<a.*?>|</a>\", \"\", s)\n",
    "                    s = re.sub(\"<img.*?>\", \"\", s)\n",
    "                    s = re.sub(\"\\n\", \"\", s)\n",
    "                    s = re.sub(\"<span.*?>|</span>\", \"\", s)\n",
    "                    s = re.sub(\"<sup>\", \"^\", s)\n",
    "                    s = re.sub(\"</sup>\", \"-\", s)\n",
    "                    s = re.sub(\"<sub>|</sub>\", \"\", s)\n",
    "\n",
    "                    c[i] = s\n",
    "        ltrs.append(c)\n",
    "\n",
    "    for i in range(len(ltrs)):\n",
    "        ltrs[i] = \"\".join(ltrs[i])\n",
    "\n",
    "\n",
    "    ## concatenated transliterations\n",
    "\n",
    "\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    l = len(ltrs)\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    for ran in nums:\n",
    "\n",
    "        ran =  ran[0]\n",
    "\n",
    "        sentence = \"\"\n",
    "\n",
    "        while(k<l-1 and lesstoe(ran, ltrs[k])):\n",
    "            if len(ltrs[k])>1 and not bool(re.search('[0-9]*?[A-Z]*?\\.', ltrs[k+1])):\n",
    "                sentence += ltrs[k+1]\n",
    "            k+=1\n",
    "\n",
    "        sentences.append(sentence)\n",
    "\n",
    "\n",
    "    for i in range(len(conts)):\n",
    "        conts[i][2] = sentences[i]\n",
    "\n",
    "    ltrs_list.extend(ltrs)\n",
    "    conts_list.extend(conts)\n",
    "    sentences_list.extend(sentences)\n",
    "    \n",
    "    \n",
    "    if j%4 == 0:\n",
    "        pd.DataFrame(conts_list).to_csv(\"data/sentence_pairs_{}.csv\".format(j), \";\", index=None, header=[\"index\", \"en\", \"akk\"])\n",
    "    #print(\"i sleep\")\n",
    "    #time.sleep(10)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem, last line not going through in some cases.\n",
    "conts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with tokenizing using tirets & not, compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_list_np = np.asarray(conts_list[:4436])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(conts_list_np[:,1:], columns=[\"en\", \"akk\"])\n",
    "df = df.append(token_pairs, sort=True, ignore_index=True)\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/6882pairs.csv\", \";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
